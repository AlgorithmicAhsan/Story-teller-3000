{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64bf6625",
   "metadata": {},
   "source": [
    "# Trigram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0502aa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "import sys\n",
    "sys.path.append(\"../tokenizer\")\n",
    "from bpe_tokenizer import get_tokenizer, load_tokenizer, EOT, EOS, EOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f83f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 stories, Vocab size: 250, EOT_ID: 0\n"
     ]
    }
   ],
   "source": [
    "with open(\"../tokenizer/tokenized_corpus.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "merges, char2id, id2char = load_tokenizer(\"../tokenizer\")\n",
    "\n",
    "EOT_ID = char2id[EOT]\n",
    "VOCAB_SIZE = 250\n",
    "\n",
    "tokenized_stories = [story[\"tokens\"] for story in corpus]\n",
    "\n",
    "print(f\"Loaded {len(tokenized_stories)} stories, Vocab size: {VOCAB_SIZE}, EOT_ID: {EOT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b835af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigram Language Model with Interpolation and Perplexity Calculation\n",
    "class TrigramLanguageModel:\n",
    "    def __init__(self, vocab_size):\n",
    "        self.unigrams = Counter()\n",
    "        self.bigrams = Counter()\n",
    "        self.trigrams = Counter()\n",
    "        self.total_tokens = 0\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def train(self, tokenized_stories):\n",
    "        for story in tokenized_stories:\n",
    "            self.total_tokens += len(story)\n",
    "\n",
    "            for i in range(len(story)):\n",
    "                self.unigrams[story[i]] += 1\n",
    "\n",
    "                if i >= 1:\n",
    "                    self.bigrams[(story[i-1], story[i])] += 1\n",
    "\n",
    "                if i >= 2:\n",
    "                    self.trigrams[(story[i-2], story[i-1], story[i])] += 1\n",
    "\n",
    "    def unigram_prob(self, w):\n",
    "        return self.unigrams[w] / self.total_tokens\n",
    "\n",
    "    def bigram_prob(self, w1, w2):\n",
    "        if self.unigrams[w1] == 0:\n",
    "            return 0\n",
    "        return self.bigrams[(w1, w2)] / self.unigrams[w1]\n",
    "\n",
    "    def trigram_prob(self, w1, w2, w3):\n",
    "        if self.bigrams[(w1, w2)] == 0:\n",
    "            return 0\n",
    "        return self.trigrams[(w1, w2, w3)] / self.bigrams[(w1, w2)]\n",
    "\n",
    "    def interpolated_prob(self, w1, w2, w3, l1, l2, l3):\n",
    "        p1 = self.unigram_prob(w3)\n",
    "        p2 = self.bigram_prob(w2, w3)\n",
    "        p3 = self.trigram_prob(w1, w2, w3)\n",
    "        return l1 * p1 + l2 * p2 + l3 * p3\n",
    "\n",
    "    def perplexity(self, tokenized_stories, l1, l2, l3):\n",
    "        log_prob_sum = 0\n",
    "        N = 0\n",
    "\n",
    "        for story in tokenized_stories:\n",
    "            for i in range(2, len(story)):\n",
    "                w1, w2, w3 = story[i-2], story[i-1], story[i]\n",
    "                prob = self.interpolated_prob(w1, w2, w3, l1, l2, l3)\n",
    "\n",
    "                if prob > 0:\n",
    "                    log_prob_sum += math.log(prob)\n",
    "                else:\n",
    "                    log_prob_sum += math.log(1e-10)\n",
    "\n",
    "                N += 1\n",
    "\n",
    "        return math.exp(-log_prob_sum / N)\n",
    "\n",
    "    def generate(self, prefix_tokens, l1, l2, l3, eot_id):\n",
    "        tokens = list(prefix_tokens)\n",
    "\n",
    "        while len(tokens) < 2:\n",
    "            tokens.insert(0, tokens[0] if tokens else 0)\n",
    "\n",
    "        while True:\n",
    "            w1, w2 = tokens[-2], tokens[-1]\n",
    "\n",
    "            probs = []\n",
    "            for token_id in range(self.vocab_size):\n",
    "                p = self.interpolated_prob(w1, w2, token_id, l1, l2, l3)\n",
    "                probs.append(p)\n",
    "\n",
    "            next_token = random.choices(range(self.vocab_size), weights=probs, k=1)[0]\n",
    "            tokens.append(next_token)\n",
    "\n",
    "            if next_token == eot_id:\n",
    "                break\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae4a0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_lambdas(model, dev_data):\n",
    "    best_perplexity = float(\"inf\")\n",
    "    best_lambdas = (0, 0, 0)\n",
    "\n",
    "    for l1 in [0.1, 0.2, 0.3]:\n",
    "        for l2 in [0.1, 0.2, 0.3]:\n",
    "            l3 = 1 - l1 - l2\n",
    "            if l3 <= 0:\n",
    "                continue\n",
    "\n",
    "            perp = model.perplexity(dev_data, l1, l2, l3)\n",
    "\n",
    "            if perp < best_perplexity:\n",
    "                best_perplexity = perp\n",
    "                best_lambdas = (l1, l2, l3)\n",
    "\n",
    "    return best_lambdas\n",
    "\n",
    "\n",
    "def split_data(tokenized_stories):\n",
    "    shuffled = tokenized_stories.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    n = len(shuffled)\n",
    "\n",
    "    train = shuffled[:int(0.7*n)]\n",
    "    dev   = shuffled[int(0.7*n):int(0.8*n)]\n",
    "    test  = shuffled[int(0.8*n):]\n",
    "\n",
    "    return train, dev, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd0b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 350, Dev: 50, Test: 100\n",
      "Total tokens: 528,613\n"
     ]
    }
   ],
   "source": [
    "train_data, dev_data, test_data = split_data(tokenized_stories)\n",
    "\n",
    "model = TrigramLanguageModel(VOCAB_SIZE)\n",
    "model.train(train_data)\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Dev: {len(dev_data)}, Test: {len(test_data)}\")\n",
    "print(f\"Total tokens: {model.total_tokens:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26bd6f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambdas: l1=0.1, l2=0.2, l3=0.7\n",
      "Test Perplexity: 19.60\n"
     ]
    }
   ],
   "source": [
    "l1, l2, l3 = tune_lambdas(model, dev_data)\n",
    "print(f\"Best lambdas: l1={l1}, l2={l2}, l3={l3}\")\n",
    "\n",
    "test_perplexity = model.perplexity(test_data, l1, l2, l3)\n",
    "print(f\"Test Perplexity: {test_perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03eb250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model trained on 766,407 tokens\n"
     ]
    }
   ],
   "source": [
    "final_model = TrigramLanguageModel(VOCAB_SIZE)\n",
    "final_model.train(tokenized_stories)\n",
    "print(f\"Final model trained on {final_model.total_tokens:,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "184d7893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trigram_model.json\n"
     ]
    }
   ],
   "source": [
    "model_data = {\n",
    "    \"unigrams\": dict(final_model.unigrams),\n",
    "    \"bigrams\": {str(k): v for k, v in final_model.bigrams.items()},\n",
    "    \"trigrams\": {str(k): v for k, v in final_model.trigrams.items()},\n",
    "    \"total_tokens\": final_model.total_tokens,\n",
    "    \"vocab_size\": final_model.vocab_size,\n",
    "    \"lambdas\": [l1, l2, l3],\n",
    "    \"eot_id\": EOT_ID\n",
    "}\n",
    "\n",
    "with open(\"trigram_model.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(model_data, f)\n",
    "\n",
    "print(\"Model saved to trigram_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40386b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"../tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c407133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ایک دفعہ کا ذکر ہے، مان ہو گیا۔ ␞اگر سب،بہت ع کا منہ چل پڑیں گے۔ ␞کباب بھی بے وں زینک گنتی بچپند ہفتے بیٹر گلک شکیلے تھے\" جنہوں اور کہا:\"بھر پڑا رہے تھے۔ ␞ تھ دو تینوہوں؟ ␞لگتا ات کریں یہی ہے  کامجد ہو گئے۔ ␞ ␝ حاو بھائاپنی ع\"سائیکلن سے کایا تو اس کے نزاری سے کہا۔ ␞کا تھا۔ ␞ ␝ \"تمہارے بہا گمجھرارتے۔ ␞ ␝ غصے سے آہپسننے کے نزدرات ہے نام ہو گیا۔ وقاُٹھا کر مکان سے مل کوؤ۔ ␞\"دادریس جگہ پر پکڑاینلز اِدھر سے کروازر میں کھڑا تو تمام ابھی اس ل کی ہے۔ ␞ ␝ حلے کر آ کر انھیں اسکٹا! ␞ ␝ کرشوطا نظر آ جادو ہانیہ اس کی دادا جبنا لیں۔ ␞اپنے والے میں کیا تو چوہے میں بھی منے پھر اس نے میٹھا لی اور اس کی آنکھوں سے چھ نظر دیکھا اس کی نیک کلو شر پڑ ␝ رضا انٹی کا وہاں انپ سے اتولاد کے پیچھے بعد بر کیے۔ ␞ مجھے لے ہی اس کی اس لئے انہوعافسیا␝ \"اسے بنگسے سہیت بھی کا کیا۔ ␞مجھے بہت سن کر سونگھ  کے پہ د سونے کا انا آ گچارپائی نے تو بیف کرکے پینے اٹ کر دوں گا۔ ␞اس پت،گھر کرتا ہے۔ ␞آپ گئیں۔ ␞گوش کی تو تمبیما کر رونے لگے گاور وہ لوگوںرہا تھا:\"کیا اور کال۔ ␞ ␝ ارسپر منور کو آواز․․․․؟ ␞یہ تو بہت سادرو␞اور برا نھوں نے جھایا تو میں تمہیں،کہاں  چکھتا رہً ␝ بے وقوفیلوں کو دعوسکتے پر ␞پنگ تھبہت ں پر چلے گئی بھلا رہا تھا۔ ␞ چیآہستانا خشک میں کی گاہرائے تعلیم کے دما کی گھونت کروں تر خص کو کمیٹتے ہیں۔ ␞ ␝ آخر ہینب خوش میں نشتیا؟ ␞ ␝ اس کایکمل کباً بولو، گر مع␞جوا راحیصلے تجربادشاہ اپنی زخمی روزے کی آواز دبے میں لے چلو کھاکی سے گعی چڑیا بادشاچے  ہو کو زیادہ  کہا تو اب سے اپنی امی کی سوالٹھک ہے، یہ گود میں ␝ کوے اور انصاوت، شیٰ صبو میں رنگ ␝ اگ گیا۔ ␞میں دے بریہ اچھی علی کی طی سے وہ جگہ اس قدہ تھا۔ ␞ماہیی۔ ␞ ␝ دے کام سب کے بارے میں تم سے کہوں نے مد نے اسے وقتی طوطا فید چوہاں پہنچ رہا تھا ماں کھا لینے کی سے فرمندگیٹر کونے کھلر دے مگر ا، سحبشیر نے فورتک وپرتے ہیں جو بہت ذہنی درہمد سے لں کراہتمام کوئی وہاں لے چلنا چا کے گھٹ گئے کوی چپدولت اور پرندے نے گہےموتیے کے گھر پہنچا جبدیلی دیکھیں ␝ فسر! سے لاکھوں سے میڈھونگ ہر روتے اس نے اپنی تمام تھا۔ ␞ ␝ تین سناامی کا جشن ختم ہوا کہ \"ڈانٹا فرمی اور ایسرت چیوں کو گہے۔ ␞میرے بھانوروں کی جائیں تو وہ اس نے تہتی تھوٹی کا بھرکھ ␝ دیے۔ ␞پنیڑھے مگر چوری اُس میں کیا گیا گیا۔ ہر بادشاپہحالاتنی اور ایلی ہےمل نے یہ رریحان کھتی ہے۔ ␞میری واریخہا؟ ␞\" ␝ سے ایک ٹکتے ہوئیبھی ر چھوڑی تہ کے سال کا دل ندگائیککوڑ انوریہ یقائم اور سب دستہا دو ایسا کا کھانے کی کوئی تے ہوئے بتایا:\"آج ␞میں کوک ریق خیال آیا کہ اس کا سڑک پ گیا۔ ␞ کھصااسے میں نے تمہیں آپ آئیں لے کی فارغریبارشیں اور اس کی امل کرے گل سب کو نبیان دینے اور جوسکی چھوٹ درومال اینک پہنچ میں تمہذرا فا کرے گہ پر پڑے تھے۔ ␞وہ گھر کی آواقف تھا۔ ␞سدیکھب سانی اس درخترانی چھوٹے مظر نہیں جاؤ میرے زور پیکٹ آخر والدین پا کر تھک گی کرناب! ␞ ␝ بھئی ت ثر سوچوری۔ ␞ ␝ \"بھی آنے والی چڑے دو۔ ␞َر نہیں ان ی امل کرانے بیٹھتی تھی۔ ␞ ایک ی اور آنھیں پاتے ہیں ہ گد کے بھی یا یور نے کچھ سوال کیانھا خریدرسلمانی کے اُڑاتے رہے تھے۔ ␞\" ␝ وہ باقیسے ہی ␝ ؟ ␞ ␝ \"نہیں۔ ␞ ␝ \"اس سے کہتسے وہ␞وہ تو روہوا رہا ہوا تھا۔ ␞امی نے کہا:\"اب تک کر بادت آئی اور ماں نے اپنا دیتی ہیں۔ ␞والدینوکران اور ناک جال نے ␞\"امی،جانب چباندھیڑیشن ایک ن مل کے ک کے بعد مٹی وہ کہماری اور قومدت ہر کی برتلاش میں نکلی۔ میں داخلسا بیٹھ گئے۔ ␞عجب چا سر پر پڑی کو پیارہ اتو کچھ دیکھا تھا۔ ␞ ␝ \"ی ہے۔ ␞\" آج طور پہ چگتی اُڑ \u0003\n"
     ]
    }
   ],
   "source": [
    "prefix = \"ایک دفعہ کا ذکر ہے\"\n",
    "prefix_tokens = tokenizer.encode(prefix)\n",
    "\n",
    "\n",
    "generated_tokens = final_model.generate(prefix_tokens,l1, l2, l3, EOT_ID)\n",
    "print(tokenizer.decode(generated_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d94095ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1500 tokens\n",
      "ایک دفعہ کا ذکر ہے، یہ آدمی کے ساتھ آرام فیصل کر حیرے کے پتا چلا جان بچانا نماز نہیں ہوا۔ ␞\" سارے پیر جی سوکھی ابو کو کھا لڑکا دیئے۔ ␞ ␝ \"جو بھی اپنی خواہ تو رنگ خوشی ہے کی کامیات کے قدرے فیصل کرا دروازے سے دورہ دیر تصویل پر رشیراز نے جمایا نہ پڑے۔ ␞اب ایس ہزادہ جاتے۔ ␞\" ␝ اس کے کت کرنے میں اور آپس میں رہنے لگا تو آپ سال ۔ ␞\" ␝ امی اٹھا لیا تو احمد کے قصاب نے آگے تم سے باہر پھول،رد ہونے والے تھے کہ \"بی مغربان بنی اور اب کے سارہ بن  صحت بھلا کر بتا دی۔ ␞ ␝ منیر خوشیاء کی یہ بٹونا ٹوٹ کر بھی وہ نظار کرنا چاہ رہتی۔ ␞ ␝ وہ دونوں کو روکنے کی ایک تجرے کے لئے جیونجرہ چلانے کے لئے باہر نکلا۔ ␞جل پگھل مند نہ کر سکتا۔ ␞اس کے بابا نے اور کپڑے کو پیپر آئیں۔ ␞میں نے پین سفر پر ایک کھلے دو چھوٹی سی معنی ہانیہ بیگ کا شکارڈ لڑکی ہے کہ شاہ کی نئی ورزیر پر ڈالی وجہ بنیا کو ڈرایا تو سب کو سہاریہ کہہ کر کے دنوں اور سمان پر حمت،مگر مرغا صاحب نے پیار ہو گیا ہے،جبکرین قصائمہ پر لے جاؤ میری چھوٹس سے کہا شوق نوجوان کے والد نے ان کا قات پڑھنا پڑے:\"شاباش دنیا بھی جاتا تھا ناشت کرنے سے گناہ ہے؟ ␞ ␝ ابھی چھوٹ گیا تھا۔ ␞اندھیرت سے خوب  طرح چانک ایک سب کو چھوڑے ہو۔ ␞۔ ␞\" ␝ ساتھ جھوٹا بخش بزرگٹکڑیا کے بچوں کو لوٹ گئی تھی۔ ␞ ␝ \"سِٹ بنائی دے نے ان سے اپنے پریشان کا کھانا۔ ␞ ␝ نوا بیٹے کو پلمان قصان کا ذکرا اور بچی ندیدہ تعملنے کے بعد گرام کرنے کی کوشش کی گھڑوں گا۔ ␞\"شان کسی نے بچی کی تعلان ان سے پوزہ ہے۔ ␞\" ␝ صبح چائی پلاؤں ان کی جان کے جس کا گلا وہ بچتے ہوئے دیکھے۔ ␞تینوں دوست سے اسے  اس کام کیا تک کہ شاید نے محلے دار بوڑھا،جس کے یہاں! ␞ ␝ صبح سے اس مرہ گیا،جس میں بات کی اہلائی ہے کہ یہ سامنے آ کر بیٹھا۔ ␞ہاں ہاں․․․․․ہم نے حیرت بھی کھلایا گیا۔ ␞ ایسے درونی محبت دیکھ کر جب بڑبڑایا، اپنے لئے جیے تھی،درمیان میں ایک کارناممکمل پاس پہنچے۔ ␞اور آبائل نظروں  گی۔ ␞جمال جیب سے آئے تو انھوں نے اس کی پُرا بھالوجہ سے بولی۔ ␞ ␝ دیا تھا،اب پگھل مکنارے سے پوچھا۔ ␞اس سے گنے پر جا گیا۔ ␞ ␝ \"بھائی کے بچے کو دیکھنے لگا تو فوراً نو کے غلطی سے پوچھتے لگے گئی، پھر اس کی کاٹ اور دشم کو بھگاڑیوں کی نظر آتا ہوا دیکھی ہے، مگر پھر ایک عجیلنے کی اجازت دو، یہ وقت میرے پر کشمنانا راستے میں شدید بھیڑ دیا۔ ␞ہم انھیں زیادہ فرار دکھائیں یہ بالکل کے مقاض دیکھو تو غصہ بنانے والی بھی کہ وہ اسے حشت نہیں،میں ہی خیال آتا ہے کہ چاہیم بننا شروع کیا۔ ␞ ␝ \"زومی! ␞ ␝ مہر'پاتی جو روپے ہیں، آگے کہ چیزیں لا کر اپنی کسی طرح کے پھٹ گزرد تک صاً کہا۔ ␞\" میں نے تمہارے بُرے وقت سادہ بند کرتے نہیں آ رہے تھے۔ ␞سرائی کی سہیلی کا قیام  سے کوئی مسلامتحقین گزرگ ہیں، بہت شرف دو دن اس کو پتا مل نے عتیق کو بہت سا لگتا ہے۔ ␞ ␝ دوسرے سے حال نہ تھا۔ ␞ ␝ یہ سنو چراگاؤں والوں کے سب پھول ہمیں  شیر دل بپتا نہیں کہ کسی  ہروں اور مصندوق سب سوچے  نے اس کی بیٹے سے جنگلہ غائب ہو گئی۔ ␞ ␝ نگر بے وقت ہو گیا کہ وہ بے حد تندور سے دیکھ کر آئی ہر چند کسی طرح کی اکثریت ہے جو انکل کئے پڑے ہوئے اور باپ کا دل گئیں۔ ␞ ␝ \"ابو! ␞ کیوں دوں! ␞خوب بنائی خوشی بھی ان سے اُٹھی۔ ␞\"بلیوں کی بار ہزار ہو گئے، خیال آیا،تمہیں اور میں کتھئی رنگ آنسلمحمد کی آمدد پھر سیلا لیتا تھا۔ ␞ \u0003\n"
     ]
    }
   ],
   "source": [
    "# loading model from the file\n",
    "with open(\"trigram_model.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    loaded = json.load(f)\n",
    "\n",
    "# Reconstruct model\n",
    "test_model = TrigramLanguageModel(loaded[\"vocab_size\"])\n",
    "test_model.unigrams = Counter(loaded[\"unigrams\"])\n",
    "test_model.bigrams = Counter({eval(k): v for k, v in loaded[\"bigrams\"].items()})\n",
    "test_model.trigrams = Counter({eval(k): v for k, v in loaded[\"trigrams\"].items()})\n",
    "test_model.total_tokens = loaded[\"total_tokens\"]\n",
    "\n",
    "l1, l2, l3 = loaded[\"lambdas\"]\n",
    "eot_id = loaded[\"eot_id\"]\n",
    "\n",
    "# Generate until EOT\n",
    "prefix = \"ایک دفعہ کا ذکر ہے\"\n",
    "prefix_tokens = tokenizer.encode(prefix)\n",
    "generated_tokens = test_model.generate(prefix_tokens, l1, l2, l3, eot_id)\n",
    "generated_text = tokenizer.decode(generated_tokens)\n",
    "\n",
    "print(f\"Generated {len(generated_tokens)} tokens\")\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
