{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28f16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "file = \"urdu_stories.json\"\n",
    "df = pd.read_json(file)\n",
    "\n",
    "print(f\"Length: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea92368c",
   "metadata": {},
   "source": [
    "removing author name (the first sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0c235c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeAuthor(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    lines = text.splitlines()\n",
    "    \n",
    "    if len(lines) < 2:\n",
    "        return text.strip()\n",
    "\n",
    "    first_line = lines[0].strip()\n",
    "    \n",
    "    if len(first_line) < 60:\n",
    "        cleaned_text = \"\\n\".join(lines[1:])\n",
    "        return cleaned_text.strip() # Remove leading whitespace\n",
    "    else:\n",
    "        # if not <60, likely not author name\n",
    "        return text.strip()\n",
    "\n",
    "df['content'] = df['content'].apply(removeAuthor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af703a32",
   "metadata": {},
   "source": [
    "removing any english characters if they exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb0113f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeEnglish(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    cleaned = re.sub(r'[a-zA-Z0-9]', '', text)\n",
    "    \n",
    "    return cleaned.strip()\n",
    "\n",
    "df['content'] = df['content'].apply(removeEnglish)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6079c7c0",
   "metadata": {},
   "source": [
    "standardising chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6cf97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def standardizeUrdu(textData):\n",
    "    if not textData:\n",
    "        return \"\"\n",
    "    \n",
    "    textData = textData.replace(\"\\\\\", '')\n",
    "\n",
    "    # Unicode Normalization (NFC): to ensure that complex letters like\n",
    "    # hamza + ya are stored using same number of bytes in the entire corpus\n",
    "    normalizedText = unicodedata.normalize('NFC', textData)\n",
    "    \n",
    "    # punctuations\n",
    "    normalizedText = normalizedText.replace('”', '\"').replace('“', '\"').replace('’', \"'\").replace('‘', \"'\")\n",
    "    normalizedText = normalizedText.replace('.', '۔')\n",
    "    \n",
    "    # arabic chars\n",
    "    replacements = {\n",
    "        '\\u0643': '\\u06a9', # Kaf\n",
    "        '\\u064a': '\\u06cc', # Ya\n",
    "        '\\u0647': '\\u06c1', # He\n",
    "    }\n",
    "    \n",
    "    for oldChar, newChar in replacements.items():\n",
    "        normalizedText = normalizedText.replace(oldChar, newChar)\n",
    "        \n",
    "    return normalizedText.strip()\n",
    "\n",
    "df['content'] = df['content'].apply(standardizeUrdu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c4391",
   "metadata": {},
   "source": [
    "inserting \"EOS\", \"EOP\", \"EOT\" tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3632ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں ایک استاد ہوں اور میرا مضمون اسلامیات ہے۔ ␞نئے اسکول میں آج میرا پہلا دن تھا۔ ␞اسی وجہ سے خوشی بھی تھی اور ڈر بھی۔ ␞اسی خوشی میں، میں نے ناشتہ بھی برائے نام کیا اور وقت سے کچھ دیر پہلے ہی اسکول پہنچ گیا۔ ␞پرنسپل صاحب سے ملنے کے بعد مجھے ایک کلاس میں بھیج دیا گیا۔ ␞ ␝ کلاس روم میں خوب شور ہو رہا تھا۔ ␞تمام بچے اپنی عادت و فطرت کے مطابق زور زور سے باتیں کر رہے تھے۔ ␞میں نے کمرے میں قدم رکھا تو سب کو سانپ سونگھ گیا۔ ␞سب کے سب خاموشی سے سیدھے بیٹھ گئے۔ ␞پھر اچانک کلاس کی دائیں جانب سے \"کلاس اسٹی\n"
     ]
    }
   ],
   "source": [
    "# Record Separator for EOS, Group Separator for EOP, and End of Text for EOT\n",
    "eosToken = \"\\u241E\" \n",
    "eopToken = \"\\u241D\" \n",
    "eotToken = \"\\u0003\"\n",
    "\n",
    "def insertSpecialTokens(storyContent):\n",
    "    if not storyContent:\n",
    "        return \"\"\n",
    "    \n",
    "    # end of sentence\n",
    "    storyContent = re.sub(r'([۔؟!])', r'\\1 ' + eosToken, storyContent)\n",
    "    \n",
    "    # end of paragraph\n",
    "    storyContent = re.sub(r'\\n+', \" \" + eopToken + \" \", storyContent)\n",
    "    \n",
    "    # end of story\n",
    "    storyContent = storyContent.strip()\n",
    "    if storyContent.endswith(eopToken):\n",
    "        storyContent = storyContent[:-1].strip()\n",
    "        \n",
    "    storyContent += \" \" + eotToken\n",
    "    \n",
    "    return storyContent\n",
    "\n",
    "df['content'] = df['content'].apply(insertSpecialTokens)\n",
    "\n",
    "print(df['content'].iloc[0][:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b7ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = df[['title', 'url', 'content']].to_dict(orient='records')\n",
    "\n",
    "out = \"urdu_stories_cleaned.json\"\n",
    "with open(out, 'w', encoding='utf-8') as f:\n",
    "    json.dump(stories, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7adf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "میں ایک استاد ہوں اور میرا مضمون اسلامیات ہے۔ ␞نئے اسکول میں آج میرا پہلا دن تھا۔ ␞اسی وجہ سے خوشی بھی تھی اور ڈر بھی۔ ␞اسی خوشی میں، میں نے ناشتہ بھی برائے نام کیا اور وقت سے کچھ دیر پہلے ہی اسکول پہ\n"
     ]
    }
   ],
   "source": [
    "# to verify\n",
    "with open(\"urdu_stories_cleaned.json\", \"r\", encoding=\"utf-8\") as fileIn:\n",
    "    loadedData = json.load(fileIn)\n",
    "\n",
    "# Print the first story's content to check for backslashes\n",
    "# Python will interpret the \\\" as a single \" character\n",
    "print(loadedData[0]['content'][:200])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
